train_loss,step,epoch
10.911883354187012,49,0
9.304367065429688,99,1
8.881895065307617,149,2
8.983343124389648,199,3
8.625991821289062,249,4
8.45630168914795,299,5
8.608295440673828,349,6
8.62871265411377,399,7
8.536306381225586,449,8
8.248676300048828,499,9
8.573493003845215,549,10
8.737483024597168,599,11
8.301846504211426,649,12
8.780163764953613,699,13
8.604316711425781,749,14
8.571972846984863,799,15
8.890089988708496,849,16
8.380218505859375,899,17
8.294808387756348,949,18
8.257417678833008,999,19
8.26175594329834,1049,20
7.983991622924805,1099,21
7.960087776184082,1149,22
7.955135345458984,1199,23
7.987306594848633,1249,24
7.969414710998535,1299,25
7.974628925323486,1349,26
7.966814041137695,1399,27
7.941460609436035,1449,28
7.9644670486450195,1499,29
7.924953460693359,1549,30
7.926549911499023,1599,31
7.936631679534912,1649,32
7.908885955810547,1699,33
7.9046478271484375,1749,34
7.919487476348877,1799,35
7.909151554107666,1849,36
7.904903411865234,1899,37
7.907405376434326,1949,38
7.8851494789123535,1999,39
7.90047550201416,2049,40
7.894904136657715,2099,41
7.889988422393799,2149,42
7.8758544921875,2199,43
7.849145889282227,2249,44
7.856005668640137,2299,45
7.865060806274414,2349,46
7.88374137878418,2399,47
7.869167327880859,2449,48
7.848098278045654,2499,49
